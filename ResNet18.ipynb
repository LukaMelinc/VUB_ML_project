{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "!pip install kaggle\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "!pip install optuna\n",
    "import optuna\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#check gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# code for importing and processing the imported data directly from Kaggle\n",
    "drive.mount('/content/drive')\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content/drive/MyDrive/kaggle\"\n",
    "!kaggle competitions download -c vub-ml-project-2024-animal-classification\n",
    "!mkdir -p /content/drive/MyDrive/kaggle\n",
    "!unzip vub-ml-project-2024-animal-classification.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# optimization with optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-1)\n",
    "    momentum = trial.suggest_uniform(\"momentum\", 0.8, 0.99)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-5, 1e-2)\n",
    "    step_size = trial.suggest_int(\"step_size\", 5, 20)\n",
    "    gamma = trial.suggest_uniform(\"gamma\", 0.1, 0.9)\n",
    "\n",
    "        # Check GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Set hyperparameters\n",
    "    EPOCH = 10\n",
    "    pre_epoch = 0\n",
    "    BATCH_SIZE = 128\n",
    "    LR = 0.01\n",
    "\n",
    "    # Define dataset directory\n",
    "    train_dir = \"/content/vub-ml-project-2024-animal-classification/train\"\n",
    "\n",
    "    # Define transformations\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),  \n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "\n",
    "    ])\n",
    "\n",
    "    # Load the dataset\n",
    "    train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    val_size = len(train_dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    num_classes = len(train_dataset.dataset.classes)\n",
    "    net = ResNet(ResidualBlock, num_classes=num_classes).to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    scheduler = StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(EPOCH):\n",
    "        net.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Validation loop\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # Calculate validation accuracy\n",
    "    val_accuracy = correct / total\n",
    "    return val_accuracy  # Optuna will maximize this metric\n",
    "\n",
    "# Create an Optuna study and optimize\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(\"Best hyperparameters:\")\n",
    "print(study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# no optimization code\n",
    "# Set hyperparameters\n",
    "EPOCH = 10\n",
    "pre_epoch = 0\n",
    "BATCH_SIZE = 128\n",
    "LR = 0.01\n",
    "\n",
    "# Define dataset directory\n",
    "train_dir = \"/content/vub-ml-project-2024-animal-classification/train\"\n",
    "\n",
    "# Define transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  \n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "\n",
    "])\n",
    "\n",
    "# Load the dataset\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform_train)\n",
    "\n",
    "# Split dataset into training and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "# Get the number of classes dynamically\n",
    "num_classes = len(train_dataset.dataset.classes)\n",
    "\n",
    "# Define ResNet18 with the correct number of output classes\n",
    "net = ResNet(ResidualBlock, num_classes=num_classes).to(device)\n",
    "\n",
    "# Define loss function & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.2)\n",
    "\n",
    "\n",
    "# StepLR/ExponentialLR: Simple decays for stable training.\n",
    "# CosineAnnealing: For tasks that benefit from smooth decay.\n",
    "# ReduceLROnPlateau: Tasks with validation monitoring needs.\n",
    "# OneCycleLR: Optimized training, often for large-scale tasks.\n",
    "# CyclicLR: Tasks requiring escape from local minima.\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(pre_epoch, EPOCH):\n",
    "    print(f'\\nEpoch: {epoch + 1}')\n",
    "    net.train()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Training loop\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward and backward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metrics for training\n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.data).cpu().sum()\n",
    "\n",
    "        print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%%' %\n",
    "              (epoch + 1, i + 1, sum_loss / (i + 1), 100. * correct / total))\n",
    "\n",
    "    # Validation loop\n",
    "    print('Validating...')\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.data).cpu().sum()\n",
    "\n",
    "    print('Validation Loss: %.3f | Validation Acc: %.3f%%' %\n",
    "          (val_loss / len(val_loader), 100. * correct / total))\n",
    "scheduler.step()\n",
    "print(f'Training complete. Total epochs: {EPOCH}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
