{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "!pip install kaggle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegressionModel:\n",
    "    def __init__(self, C=1.0, max_iter=100, random_state=42):\n",
    "        self.model = LogisticRegression(C=C, max_iter=max_iter, random_state=random_state)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        return accuracy\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.model.get_params()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RandomForestModel:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, random_state=42):\n",
    "        self.model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        return accuracy\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.model.get_params()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SVMModel:\n",
    "    def __init__(self, kernel='rbf', C=1.0, gamma='scale', random_state=42):\n",
    "        self.model = SVC(kernel=kernel, C=C, gamma=gamma, random_state=random_state)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        predictions = self.model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        return accuracy\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.model.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# code for importing and processing the imported data directly from Kaggle\n",
    "drive.mount('/content/drive')\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"/content/drive/MyDrive/kaggle\"\n",
    "!kaggle competitions download -c vub-ml-project-2024-animal-classification\n",
    "!mkdir -p /content/drive/MyDrive/kaggle\n",
    "!unzip vub-ml-project-2024-animal-classification.zip -d /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append('/content/vub-ml-project-2024-animal-classification/starterskit/')\n",
    "\n",
    "# Path to your feature file\n",
    "feature_file_path = '/content/vub-ml-project-2024-animal-classification/starterskit/features/train/train_features_vgg.pkl'\n",
    "\n",
    "# Load the pickle file\n",
    "with open(feature_file_path, 'rb') as f:\n",
    "    features_data = pickle.load(f)\n",
    "\n",
    "# Check the type of the loaded data\n",
    "print(type(features_data))\n",
    "\n",
    "# Check the number of feature vectors in the list\n",
    "print(f\"Number of features: {len(features_data)}\")\n",
    "# Inspect the first feature vector\n",
    "first_feature = features_data[0]\n",
    "print(f\"Type of the first feature: {type(first_feature)}\")\n",
    "print(f\"First feature content: {first_feature}\")\n",
    "import features\n",
    "if isinstance(first_feature, features.ImageFeatures):\n",
    "    print(f\"Label of the first feature: {first_feature.label}\")  # Replace 'label' with the correct attribute name\n",
    "# Check the shape of a feature vector\n",
    "first_feature_data = first_feature.data\n",
    "print(f\"Shape of the first feature vector: {first_feature_data.shape}\")\n",
    "\n",
    "# Optionally, check a few more examples\n",
    "for i in range(5):\n",
    "    print(f\"Feature {i}: Shape: {features_data[i].data.shape}, Label: {features_data[i].label}\")\n",
    "# Extract labels\n",
    "labels = [feature.label for feature in features_data]\n",
    "label_df = pd.Series(labels)\n",
    "\n",
    "# Print the distribution of labels\n",
    "print(\"Label distribution:\")\n",
    "print(label_df.value_counts())\n",
    "\n",
    "# Plot the distribution of labels\n",
    "label_df.value_counts().plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Label Distribution')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check dimensions of all feature vectors\n",
    "feature_shapes = [feature.data.shape for feature in features_data]\n",
    "\n",
    "# Identify unique shapes\n",
    "unique_shapes = set(feature_shapes)\n",
    "print(f\"Unique feature shapes: {unique_shapes}\")\n",
    "\n",
    "# Optionally, count occurrences of each shape\n",
    "from collections import Counter\n",
    "shape_counts = Counter(feature_shapes)\n",
    "print(f\"Shape counts: {shape_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# padding the image\n",
    "# Determine the max height and width\n",
    "max_height = max(feature.data.shape[0] for feature in features_data)\n",
    "max_width = max(feature.data.shape[1] for feature in features_data)\n",
    "\n",
    "# Pad all feature matrices to the size (max_height, max_width)\n",
    "X_padded = np.array([np.pad(feature.data, \n",
    "                            ((0, max_height - feature.data.shape[0]), \n",
    "                             (0, max_width - feature.data.shape[1])), \n",
    "                            mode='constant', constant_values=0).flatten() \n",
    "                     for feature in features_data])\n",
    "\n",
    "# Check the shape of X (should be num_samples x feature_length)\n",
    "print(f\"Feature matrix shape: {X_padded.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Assume X and y are your feature matrix and target labels\n",
    "X = X_padded  # Feature matrix (after scaling)\n",
    "y = np.array([feature.label for feature in features_data])  # Labels\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model you want to use\n",
    "model = RandomForestModel(n_estimators=100, max_depth=10)\n",
    "\n",
    "# Training the model\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
